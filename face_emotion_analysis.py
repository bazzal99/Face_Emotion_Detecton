# -*- coding: utf-8 -*-
"""Face_Emotion_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JxshC8ZrtxqoIdaV7cAkp97VYjIvS909
"""

from google.colab import drive
drive.mount('/content/drive')

import sys, os
import pandas as pd
import numpy as np

import keras
from keras.models import Sequential
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D
from keras.losses import categorical_crossentropy
from keras.optimizers import Adam, SGD
from keras.regularizers import l2
from keras.utils import np_utils

num_features = 64
num_labels = 7
batch_size = 64
epochs = 200
width, height = 48, 48

df=pd.read_csv('/content/drive/My Drive/icml_face_data.csv')
#print(df.info())
print(df[' Usage'].value_counts())
#print(df.head())
#print(df)
for col in df.columns: 
    print(col)

X_train,train_y,X_test,test_y=[],[],[],[]

for index, row in df.iterrows():
    val=row[" pixels"].split(" ")
    if 'Training' in row[' Usage']:
       X_train.append(np.array(val,'float32'))
       train_y.append(row['emotion'])
    elif 'PublicTest' in row[' Usage']:
       X_test.append(np.array(val,'float32'))
       test_y.append(row['emotion'])

X_train = np.array(X_train,'float32')
train_y = np.array(train_y,'float32')
X_test = np.array(X_test,'float32')
test_y = np.array(test_y,'float32')

train_y=np_utils.to_categorical(train_y, num_classes=num_labels)
test_y=np_utils.to_categorical(test_y, num_classes=num_labels)

X_train -= np.mean(X_train, axis=0)
X_train /= np.std(X_train, axis=0)

X_test -= np.mean(X_test, axis=0)
X_test /= np.std(X_test, axis=0)

X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)
X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)

print(X_train.shape)

# model = Sequential()
# model.add(Conv2D(128, kernel_size = (7, 7), input_shape=(width,height,1), activation= 'relu',padding='same' ))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.5))

# model.add(Conv2D(64, kernel_size = (5, 5), activation= 'relu',padding='same' ))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.3))

# model.add(Conv2D(32, kernel_size = (3, 3), activation= 'relu',padding='same' ))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.3))

# model.add(Conv2D(16, kernel_size = (3, 3), activation= 'relu',padding='same' ))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.2))

# model.add(Flatten())
# model.add(Dense(1024, activation= 'relu' ))
# model.add(Dense(512, activation= 'relu' ))
# model.add(Dense(num_labels, activation= 'softmax' ))

# opt = keras.optimizers.Adam(lr=0.0001)
# model.compile(loss= 'categorical_crossentropy' ,optimizer=opt , metrics=[ 'accuracy' ])

model = Sequential()
model.add(Conv2D(64, (1, 1), padding='same', activation='relu', input_shape=(width,height,1)))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(Conv2D(128, (3, 3),padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(Conv2D(256, (5, 5),padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2, 2),padding="same"))
model.add(Dropout(0.25))


model.add(Flatten())

model.add(Dense(128, activation= 'relu' ))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(Dense(256, activation= 'relu' ))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(Dense(7, activation='softmax'))
model.summary()


opt = keras.optimizers.Adam(lr=0.0001)
model.compile(loss= 'categorical_crossentropy' ,optimizer=opt , metrics=[ 'accuracy' ])

# model.fit(X_train, Y_train, batch_size=64, epochs=40, steps_per_epoch=(len(X_train)/128))


# model.fit(X_train, Y_train, batch_size=64, epochs=40, steps_per_epoch=len(X_train)/128, validation_split = 0.25)

# model.save('CNNmodel')

earlystop = EarlyStopping(patience=7)
callbacks = [earlystop]
history = model.fit(x = X_train, y = train_y, epochs=epochs, batch_size = batch_size, shuffle=True,validation_data=(X_test, test_y), callbacks=callbacks)

model_path="/content/drive/My Drive/CNNmodel.h5"
model.save(model_path)

